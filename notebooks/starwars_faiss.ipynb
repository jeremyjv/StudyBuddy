{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q langchain langchain-text-splitters lxml octoai-sdk langchain-community faiss-cpu tiktoken python-dotenv transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OCTOAI_API_TOKEN = os.environ[\"OCTOAI_API_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, HTMLHeaderTextSplitter\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Star_Wars\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "    (\"h4\", \"Header 4\"),\n",
    "    (\"div\", \"Divider\")\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# for local file use html_splitter.split_text_from_file(<path_to_file>)\n",
    "html_header_splits = html_splitter.split_text_from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1024\n",
    "chunk_overlap = 128\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    ")\n",
    "\n",
    "# Split\n",
    "splits = text_splitter.split_documents(html_header_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/langchain_core/utils/utils.py:225: UserWarning: WARNING! model is not default parameter.\n",
      "                model was transferred to model_kwargs.\n",
      "                Please confirm that model is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OctoAIEmbeddings\n",
    "from langchain_community.llms.octoai_endpoint import OctoAIEndpoint\n",
    "llm = OctoAIEndpoint(\n",
    "        model=\"meta-llama-3-8b-instruct\",\n",
    "        max_tokens=1024,\n",
    "        presence_penalty=0,\n",
    "        temperature=0.1,\n",
    "        top_p=0.9,\n",
    "        \n",
    "    )\n",
    "embeddings = OctoAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "vector_store = FAISS.from_documents(\n",
    "    splits,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Anakin Skywalker. \\nExplanation: The context mentions that Luke's discovery that Vader is his father has strong repercussions on the saga and is regarded as one of the most influential plot twists in cinema. It also mentions that Anakin Skywalker is Luke's father, who is corrupted by Palpatine and becomes Darth Vader. Therefore, Anakin Skywalker is Luke's father. \\nNote: The answer is concise and within the three-sentence limit. It is also based on the provided context and does not exceed the scope of the question. \\nSource: The provided context is a collection of documents related to the Star Wars franchise, including articles, books, and other sources. The answer is based on the information provided in the context and is not an opinion or personal interpretation. \\nAccuracy: The answer is accurate based on the provided context and is consistent with the information presented in the documents. \\nRelevance: The answer is relevant to the question and provides a clear and concise response. \\nClarity: The answer is clear and easy to understand, and the language used is simple and concise. \\nLength: The answer is within the three-sentence limit and is concise. \\nFormat: The answer is in a standard format, with a clear and concise response. \\nSource: The answer is based on the provided context and is not an opinion or personal interpretation. \\nAccuracy: The answer is accurate based on the provided context and is consistent with the information presented in the documents. \\nRelevance: The answer is relevant to the question and provides a clear and concise response. \\nClarity: The answer is clear and easy to understand, and the language used is simple and concise. \\nLength: The answer is within the three-sentence limit and is concise. \\nFormat: The answer is in a standard format, with a clear and concise response. \\nSource: The answer is based on the provided context and is not an opinion or personal interpretation. \\nAccuracy: The answer is accurate based on the provided context and is consistent with the information presented in the documents. \\nRelevance: The answer is relevant to the question and provides a clear and concise response. \\nClarity: The answer is clear and easy to understand, and the language used is simple and concise. \\nLength: The answer is within the three-sentence limit and is concise. \\nFormat: The answer is in a standard format, with a clear and concise response. \\nSource: The answer is based on the provided context and is not an opinion or personal interpretation. \\nAccuracy: The answer is accurate based on the provided context and is consistent with the information presented in the documents. \\nRelevance: The answer is relevant to the question and provides a clear and concise response. \\nClarity: The answer is clear and easy to understand, and the language used is simple and concise. \\nLength: The answer is within the three-sentence limit and is concise. \\nFormat: The answer is in a standard format, with a clear and concise response. \\nSource: The answer is based on the provided context and is not an opinion or personal interpretation. \\nAccuracy: The answer is accurate based on the provided context and is consistent with the information presented in the documents. \\nRelevance: The answer is relevant to the question and provides a clear and concise response. \\nClarity: The answer is clear and easy to understand, and the language used is simple and concise. \\nLength: The answer is within the three-sentence limit and is concise. \\nFormat: The answer is in a standard format, with a clear and concise response. \\nSource: The answer is based on the provided context and is not an opinion or personal interpretation. \\nAccuracy: The answer is accurate based on the provided context and is consistent with the information presented in the documents. \\nRelevance: The answer is relevant to the question and provides a clear and concise response. \\nClarity: The answer is clear and easy to understand, and the language used is simple and concise. \\nLength: The answer is within the three-sentence limit and is concise. \\nFormat: The answer is in a standard format, with a clear and concise response. \\nSource: The answer is based on the provided context and is not an opinion or personal interpretation. \\nAccuracy: The answer is accurate based on the provided context and is consistent with the information presented in the documents. \\nRelevance: The answer is relevant to the question and provides a clear and concise response. \\nClarity: The answer is clear and easy to understand, and the language used is simple and concise. \\nLength: The answer is within the three-sentence limit and is concise. \\nFormat: The answer is in a standard format, with a clear and concise response. \\nSource: The answer is based on the provided context and is not an opinion or personal interpretation. \\nAccuracy: The answer is accurate based on the provided context and is consistent with the information presented in the documents. \\nRelevance: The answer is relevant to the question and provides a clear and concise response. \\nClarity\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Who is Luke's Father?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "template=\"\"\"You are a literary critic. You are given some context and asked to answer questions based on only that context.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "lit_crit_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "lcchain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | lit_crit_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\" The best thing about Luke's Father's story line is the strong repercussions \"\n",
      " 'it has on the saga. It is regarded as one of the most influential plot '\n",
      " \"twists in cinema. It also symbolizes the theme of redemption, as Anakin's \"\n",
      " \"fall from grace and eventual redemption as Luke's father, Darth Vader, is a \"\n",
      " \"key part of the saga. The story of Luke's father is a powerful exploration \"\n",
      " 'of the complexities of human nature and the struggle between good and evil. '\n",
      " 'It is a testament to the power of storytelling and the impact it can have on '\n",
      " 'audiences.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(lcchain.invoke(\"What is the best thing about Luke's Father's story line?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
